{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIahtV1JovAX","executionInfo":{"status":"ok","timestamp":1713608676336,"user_tz":-120,"elapsed":22614,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"bb1fcbb4-f554-4eb1-9da9-ea3134efba63"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/MSc_AI/Year 1/P5_Data_Mining"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYUgN49jox8m","executionInfo":{"status":"ok","timestamp":1713608676615,"user_tz":-120,"elapsed":282,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"7545d1c0-baf0-404a-d53e-c912361ecd02"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MSc_AI/Year 1/P5_Data_Mining\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YuVWttwuoqy-","executionInfo":{"status":"ok","timestamp":1713608684712,"user_tz":-120,"elapsed":8099,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","import torch"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Zn-_ytfxoqzG","executionInfo":{"status":"ok","timestamp":1713608685109,"user_tz":-120,"elapsed":417,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}}},"outputs":[],"source":["df = pd.read_csv(\"mood_df.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SyVR_4_oqzI","executionInfo":{"status":"ok","timestamp":1713608685110,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"26565380-de9b-49b0-fba6-78a5bc522f1c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['meancircumplex.arousal', 'meancircumplex.valence', 'sumactivity',\n","       'sumappCat.builtin', 'sumappCat.communication',\n","       'sumappCat.entertainment', 'sumappCat.finance', 'sumappCat.game',\n","       'sumappCat.office', 'sumappCat.other', 'sumappCat.social',\n","       'sumappCat.travel', 'sumappCat.unknown', 'sumappCat.utilities',\n","       'sumappCat.weather', 'sumcall', 'sumscreen', 'sumsms', 'countactivity',\n","       'countappCat.builtin', 'countappCat.communication',\n","       'countappCat.entertainment', 'countappCat.finance', 'countappCat.game',\n","       'countappCat.office', 'countappCat.other', 'countappCat.social',\n","       'countappCat.travel', 'countappCat.unknown', 'countappCat.utilities',\n","       'countappCat.weather', 'countcall', 'countcircumplex.arousal',\n","       'countcircumplex.valence', 'countscreen', 'countsms', 'id',\n","       'timestamps', 'y', 'circumplex_rad', 'circumplex_degree'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}],"source":["df.columns"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woadk51ZoqzJ","executionInfo":{"status":"ok","timestamp":1713611056965,"user_tz":-120,"elapsed":7399,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"6bedee86-df91-4535-c2c3-8564c132dc96"},"outputs":[{"output_type":"stream","name":"stdout","text":["['AS14.01' 'AS14.02' 'AS14.03' 'AS14.05' 'AS14.06' 'AS14.07' 'AS14.08'\n"," 'AS14.09' 'AS14.12' 'AS14.13' 'AS14.14' 'AS14.15' 'AS14.16' 'AS14.17'\n"," 'AS14.19' 'AS14.20' 'AS14.23' 'AS14.24' 'AS14.25' 'AS14.26' 'AS14.27'\n"," 'AS14.28' 'AS14.29' 'AS14.30' 'AS14.31' 'AS14.32' 'AS14.33']\n"]}],"source":["# A list of all unique people, we can make time series per person.\n","unique_people = df['id'].unique()\n","print(unique_people)\n","\n","\n","ts_idx = df.columns.get_loc('timestamps')\n","y_idx = df.columns.get_loc('y')\n","\n","df['timestamps'] = pd.to_datetime(df['timestamps'])\n","\n","# The amount of consequtive days:\n","days = 4\n","\n","X = []\n","y = []\n","\n","for person in unique_people:\n","    one_person_df = df[df['id'] == person]\n","    #print(one_person_df.columns)\n","    for row in one_person_df.values:\n","        n_days = []\n","        for d in range(days, 0, -1):\n","\n","            prev_day = row[ts_idx] - pd.DateOffset(days=d)\n","            if prev_day in one_person_df['timestamps'].values:\n","                day_df = one_person_df[one_person_df['timestamps'] == prev_day]\n","                day_df = day_df.drop(columns=['id', 'timestamps', 'y'], axis = 1)\n","                arrays = day_df.values\n","                lst = arrays.tolist()\n","                n_days.append(lst[0])\n","            #    day_features.append(one_person_df.drop('y', axis=1))\n","        #n_days_tensor = torch.tensor(n_days)\n","        X.append(n_days)\n","        y.append(row[y_idx])\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"2azO3Q7voqzL","executionInfo":{"status":"ok","timestamp":1713611056966,"user_tz":-120,"elapsed":5,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}}},"outputs":[],"source":["X_new = []\n","y_new = []\n","\n","for idx, i in enumerate(X):\n","    if len(i) ==days:\n","        X_new.append(i)\n","        new_y = [0,0,0]\n","        new_y[int(y[idx])] = 1\n","        #y_new.append(new_y)\n","        y_new.append(y[idx])"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZLyBH8poqzL","executionInfo":{"status":"ok","timestamp":1713611056967,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"6033e666-3cb7-470b-92ab-b0662888aa9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["1245\n","1071\n","1071\n","[[0.3, 0.0769230769230768, -0.3428848718743589, -0.7763694781866928, -0.3125239211136217, -0.9557345429130516, -0.9605963273593408, -1.0, -1.0, -0.9145335913909204, -0.960882355440416, -0.9558289923078152, -1.0, -0.869318566893948, -1.0, -0.8064516129032258, -0.2025963623672804, -0.8823529411764706, 0.3333333333333332, -0.506631299734748, -0.4037267080745341, -0.9867109634551496, -0.8636363636363636, -1.0, -1.0, -0.7083333333333333, -0.8562874251497006, -0.9736842105263158, -1.0, -0.922077922077922, -1.0, -0.8064516129032258, 0.6666666666666667, 0.3333333333333332, -0.3101604278074866, -0.8823529411764706, -0.3513940678868148, 0.1958794243699566], [0.1, 0.2615384615384615, -0.6287785754309916, -0.6968223898369763, -0.3805408502320461, -0.9552497876824264, -0.9188537861253304, -1.0, -1.0, -0.9365831462851246, -0.919845007170972, -1.0, -1.0, -0.9665733024168416, -0.7996683775221933, -1.0, -0.1205899228178981, -1.0, 0.25, -0.4482758620689655, -0.3975155279503105, -0.9800664451827242, -0.8181818181818181, -1.0, -1.0, -0.75, -0.7844311377245509, -1.0, -1.0, -0.974025974025974, -0.8666666666666667, -1.0, 0.6666666666666667, 0.6666666666666667, -0.4598930481283422, -1.0, -0.3151894296658531, 0.4032738345196767], [0.3999999999999999, -0.2307692307692307, -0.6714383454674846, -0.5933233152258426, -0.0142460750673115, -0.8169517765781167, -0.9362354498442624, -1.0, -0.9962629516350208, -0.942038930701088, -0.7131677037589756, -0.9585523086914642, -1.0, -0.9888185107865152, -1.0, -0.3548387096774194, 0.6732596363222658, -1.0, 1.0, -0.0769230769230768, 0.1925465838509317, -0.9534883720930232, -0.7272727272727273, -1.0, -0.9907407407407408, -0.75, -0.4850299401197605, -0.8947368421052632, -1.0, -0.974025974025974, -1.0, -0.3548387096774194, 0.6666666666666667, 0.6666666666666667, 0.0374331550802138, -1.0, -0.3356361611700802, -0.0324354879227454], [0.25, 0.0769230769230768, -0.5906594627752496, -0.7144520386817472, 0.1225011743249553, -0.967648517358103, -0.9195062762444988, -1.0, -1.0, -0.8442780664839363, -0.8292090104441224, -1.0, -0.661228660536638, -0.7523573454629086, -1.0, -1.0, 0.2358078334942961, -0.8823529411764706, 1.0, -0.4641909814323607, -0.0931677018633539, -0.9867109634551496, -0.8181818181818181, -1.0, -1.0, -0.75, -0.6646706586826348, -1.0, -0.2727272727272727, -0.7402597402597403, -1.0, -1.0, 0.3333333333333332, 0.3333333333333332, -0.3529411764705882, -0.8823529411764706, -0.4127797804852965, 0.225673384057941]]\n","1.0\n"]}],"source":["print(len(X))\n","print(len(X_new))\n","print(len(y_new))\n","print(X_new[0])\n","print(y_new[0])"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"WVLzMQQboqzM","executionInfo":{"status":"ok","timestamp":1713611058013,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPeHGzjWoqzO","executionInfo":{"status":"ok","timestamp":1713611060323,"user_tz":-120,"elapsed":301,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"e4bd5255-a072-4f1f-a599-ff3b7b564e8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["['AS14.01' 'AS14.02' 'AS14.03' 'AS14.05' 'AS14.06' 'AS14.07' 'AS14.08'\n"," 'AS14.09' 'AS14.12' 'AS14.13' 'AS14.14' 'AS14.15' 'AS14.16' 'AS14.17'\n"," 'AS14.19' 'AS14.20' 'AS14.23' 'AS14.24' 'AS14.25' 'AS14.26' 'AS14.27'\n"," 'AS14.28' 'AS14.29' 'AS14.30' 'AS14.31' 'AS14.32' 'AS14.33']\n"]}],"source":["print(unique_people)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C31OFNknoqzO","executionInfo":{"status":"ok","timestamp":1713616992486,"user_tz":-120,"elapsed":201,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"61a5bf40-8ce0-43df-9f2e-6d652468c640"},"outputs":[{"output_type":"stream","name":"stdout","text":["856\n","856\n","1626\n","1626\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","from imblearn.over_sampling import SMOTE\n","\n","\n","# Define a custom dataset class\n","class TimeSeriesDataset(Dataset):\n","    def __init__(self, data, target):\n","        self.data = data\n","        self.target = target\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # Get the data and target for the current index\n","        sample = {'data': self.data[idx], 'target': self.target[idx]}\n","        return sample\n","\n","# Assuming you have lists of features and targets for your time series data\n","# Example: features = [feature_day1, feature_day2, ..., feature_day5]\n","# Example: targets = [target1, target2, ..., targetN]\n","\n","# Convert X_train to a numpy array\n","X_train_array = np.array(X_train)\n","\n","X_reshaped = []\n","for xss in X_train_array:\n","    new_x = []\n","    for xs in xss:\n","        for x in xs:\n","            new_x.append(x)\n","    X_reshaped.append(new_x)\n","\n","print(len(X_reshaped))\n","print(len(y_train))\n","\n","# Fit and apply the resampling\n","oversampler = SMOTE()\n","X_train_resampled_flattened, y_train_resampled = oversampler.fit_resample(X_reshaped, y_train)\n","\n","# Reshape back\n","X_train_resampled = []\n","for xs in X_train_resampled_flattened:\n","    sub_list = [xs[i:i+len(X_train_array[0][0])] for i in range(0, len(xs), len(X_train_array[0][0]))]\n","    X_train_resampled.append(sub_list)\n","\n","\n","print(len(X_train_resampled))\n","print(len(y_train_resampled))\n","\n","\n","\n","# Convert lists to numpy arrays\n","# train_features_array = np.array(X_train_resampled)\n","# train_targets_array = np.array(y_train_resampled)\n","train_features_array = np.array(X_train)\n","train_targets_array = np.array(y_train)\n","test_features_array = np.array(X_test)\n","test_targets_array = np.array(y_test)\n","\n","\n","# Create a dataset instance\n","train_dataset = TimeSeriesDataset(train_features_array, train_targets_array)\n","test_dataset = TimeSeriesDataset(test_features_array, test_targets_array)\n","\n","# Define batch size and shuffle option\n","batch_size = 1\n","shuffle = True  # Shuffle the data for training\n","\n","# Create a DataLoader instance\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n","\n"]},{"cell_type":"code","source":["for batch in train_loader:\n","    print(batch['target'])\n","\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wT8UDu8kzPyJ","executionInfo":{"status":"ok","timestamp":1713616995274,"user_tz":-120,"elapsed":210,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"52bcca10-00fa-4811-bf0c-7a7ca1860811"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.], dtype=torch.float64)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UN5nvXagoqzQ","outputId":"0567b4ae-e4cb-4393-cf93-af0df88f88f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/300], Train Loss: 3.6627\n","Epoch [2/300], Train Loss: 3.6108\n","Epoch [3/300], Train Loss: 3.5956\n","Epoch [4/300], Train Loss: 3.6308\n","Epoch [5/300], Train Loss: 3.5629\n","Epoch [6/300], Train Loss: 3.5529\n","Epoch [7/300], Train Loss: 3.5428\n","Epoch [8/300], Train Loss: 3.5776\n","Epoch [9/300], Train Loss: 3.5112\n"]}],"source":["import torch\n","import torch.nn as nn\n","import tqdm\n","from sklearn.metrics import classification_report\n","\n","\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(LSTMModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])  # Use the output of the last time step\n","        return out\n","\n","\n","# Define hyperparameters\n","input_size = len(X_new[0][0])       # Number of features\n","hidden_size = len(X_new[0][0])*2     # Number of hidden units in LSTM\n","num_layers = 4                     # Number of LSTM layers\n","output_size = 3                     # Output size\n","\n","# Create an instance of the LSTM model\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","\n","\n","# Train the model\n","num_epochs = 300\n","loss = 1\n","patience = 10\n","val_loss = 10\n","best_val_loss = 10\n","for epoch in range(num_epochs):\n","    for batch in train_loader:\n","\n","        inputs = batch['data'].float()  # Convert inputs to float\n","        targets = batch['target'].long()  # Convert targets to long\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    with torch.no_grad():\n","        for batch in train_loader:\n","            inputs = batch['data'].float()  # Convert inputs to float\n","            targets = batch['target'].long()\n","            outputs = model(inputs)\n","            val_loss += criterion(outputs, targets).item()\n","    val_loss /= len(test_loader)\n","\n","    # Check for early stopping\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        counter = 0\n","    else:\n","        counter += 1\n","\n","    # Print validation loss\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {val_loss:.4f}')\n","\n","    # Check if early stopping criteria met\n","    if counter >= patience:\n","        print(f'Train loss not decreasing for {patience} epochs. Stopping training.')\n","        break"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQVonUcZoqzQ","executionInfo":{"status":"ok","timestamp":1713612841934,"user_tz":-120,"elapsed":350,"user":{"displayName":"Tom Slik","userId":"02168165989802306480"}},"outputId":"ac0959cd-f0c3-4701-c857-10597be2ae62"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n","        1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n","        1, 1, 2, 0, 0, 1, 1, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1,\n","        1, 0, 1, 0, 0, 2, 0, 1, 1, 0, 1, 2, 2, 2, 0, 1, 1, 2, 1, 1, 2, 1, 1, 0,\n","        1, 1, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 2, 1, 1, 2, 0,\n","        1, 1, 2, 1, 1, 0, 2, 1, 0, 2, 0, 2, 1, 2, 0, 0, 0, 1, 2, 1, 1, 2, 2, 0,\n","        1, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n","        1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n","        1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1])\n","[1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       0.23      0.27      0.24        45\n","         1.0       0.61      0.59      0.60       130\n","         2.0       0.22      0.20      0.21        40\n","\n","    accuracy                           0.45       215\n","   macro avg       0.35      0.35      0.35       215\n","weighted avg       0.46      0.45      0.45       215\n","\n"]}],"source":["# Set the model to evaluation mode\n","model.eval()\n","\n","# Define a list to store the predictions\n","predictions = []\n","\n","# Disable gradient computation\n","with torch.no_grad():\n","    # Iterate over the test DataLoader\n","    for batch in train_loader:\n","        inputs = batch['data'].float()  # Get input features for the batch\n","        # Forward pass\n","        outputs = model(inputs)\n","        max_values, max_indices = torch.max(outputs, dim=1)\n","        # Append the predictions to the list\n","        predictions.append(max_indices)\n","\n","# Concatenate the predictions\n","predictions = torch.cat(predictions, dim=0)\n","\n","# Now you can evaluate the predictions as needed\n","y_pred = predictions.round().flatten()\n","\n","print(y_pred)\n","print(y_test)\n","\n","report = classification_report(y_test, y_pred)\n","\n","print(\"Classification Report:\")\n","print(report)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}